// This file is auto-generated. Do not edit manually.
import { WritingPost } from '../utils/markdownLoader'

export const posts: WritingPost[] = [
  {
    "slug": "table",
    "title": "Table",
    "date": "2025-08-19",
    "content": "\n![Example of a grouped data table showing food items organized by type, with filtering and grouping controls](/table-example.png)\n\n## Background\n\n- Product teams gave us two key pieces of feedback: our existing table component was hard to extend, and teams were duplicating work when adding new features.\n- This was a perfect opportunity for a platform team to provide a good abstraction.\n- An abstracted component could also enforce best practices and enable otherwise nice-to-have features like analytics tracking.\n\n## The Scale of the Problem\n\nBefore diving into solutions, let's understand the scope. Tables weren't just another component — they were one of our most-used design elements across the entire product. We found many table features that teams were implementing independently:\n\n- Headers and sub-headers\n- Column sorting and filtering\n- Row multi-select & bulk actions\n- Pagination\n- Sticky headers and columns\n- Column visibility controls\n- Row grouping\n- Column resizing\n\nEach product team was building their own table implementation, leading to inconsistent user experiences and massive code duplication. We also had multiple table components (`design-system/Table`, `components/ListTable`) with different APIs, creating confusion for developers.\n\n## Decision Making: New Component vs. Refactor\n\n### The Bake-off Process\n\n- Our first decision was whether we needed to introduce a new component or if we could refactor our existing one (preferred).\n- If you create a new component, you need to plan for migration from old to new, which is usually harder than it seems.\n- You also risk an unfinished migration if priorities change. Having two systems is harder to maintain, so incremental change is preferred.\n- You might want a new component when the API or usage is changing so significantly that refactoring wouldn't be worth it.\n\n### Third-Party Library Evaluation\n\nRather than building everything from scratch, we evaluated existing table libraries. This wasn't just a quick comparison - we actually prototyped recreating simple existing tables with different libraries to evaluate their documentation, developer experience, and flexibility.\n\nWe evaluated several options including `fixed-data-table-2`, `react-table` (v7), and `chakra/table`. The outcome was that we'd use Tanstack Table (the successor to react-table v7).\n\nWhy Tanstack Table?\n\n- Strong TypeScript support and widespread industry adoption\n- Extremely flexible and configurable for future needs\n- Major version upgrade from our existing `react-table` dependency, simplifying migration\n- Headless architecture that gives us full control over styling and behavior\n\nThe trade-off: Tanstack Table requires time to set up the UI (it's headless), but we had the resources to build opinionated components on top. This gave us the best of both worlds - a battle-tested foundation with complete design control.\n\nHowever, this did mean we now had a migration challenge to solve!\n\n## Technical Implementation\n\n### Guiding Principles\n\n**Consumers Control State**\n\nOne of our most important decisions was that consumers own state. This principle came from hard-learned lessons with other components where we tried to \"magic away\" state management.\n\nWhen you abstract state too much, you end up with a component that's harder to use and understand. By keeping state management explicit, you give developers the flexibility they need while maintaining clarity. This also enables use cases like using the same data for both a table and a data visualization.\n\n```tsx\n// ✅ Explicit state management\n\nconst [sorting, setSorting] = useState<SortingState>({\n  id: 'name',\n  desc: false,\n})\nconst [pagination, setPagination] = useState<PaginationState>({\n  pageIndex: 0,\n  pageSize: 50,\n})\n\nconst table = useDataTable({\n  columns,\n  data,\n  state: { sorting, pagination },\n  onSortingChange: setSorting,\n  onPaginationChange: setPagination,\n})\n```\n\n**Lean into JSX and Composition**\n\nInstead of a monolithic `<Table />` with many props (which leads to prop bloat), we split it up and make you import and pass in the content. This makes it much easier to work with the internals of the component.\n\n```tsx\n// ❌ Monolithic approach with potential for prop bloat\n\n<Table\n  data={data}\n  rowClassNamesCallback={(data, index) => {\n    return index % 2 === 0 ? \"bg-gray-400\" : \"bg-white\"\n  }}\n/>\n\n// ✅ Compositional approach\n\n<DataTable {...table}>\n  <DataTable.Body>\n    {table.getRows().map((row, index) => (\n      <DataTable.Row\n        key={row.id}\n        row={row}\n        className={index % 2 === 0 ? \"bg-gray-400\" : \"bg-white\"}\n      />\n    ))}\n  </DataTable.Body>\n</DataTable>\n```\n\nYou maintain the expressiveness of JSX and you're not blocked by the DS team or have to add props to the main component.\n\nExtending the table to include controls is similarly straightforward:\n\n```tsx\n<DataTable.Wrapper>\n  <DataTable.Controls>\n    <DataTable.Search />\n    <DataTable.ColumnVisibility />\n  </DataTable.Controls>\n\n  <DataTable {...table} />\n\n  <DataTable.Controls>\n    <DataTable.Pagination />\n  </DataTable.Controls>\n</DataTable.Wrapper>\n```\n\nThis approach provides several benefits:\n\n### SimpleTable Pattern\n\nWe got feedback that developers want a simple table without all the complexity. For these cases, we tried to provide a `SimpleTable`:\n\n```tsx\n// ✅ Simple use case - just pass data and columns\n\n<SimpleTable columns={columns} data={data} />\n\n// ✅ Complex use case - full control over structure\n\n<DataTable {...table}>\n  <DataTable.Head />\n  <DataTable.Body />\n  <DataTable.Controls>\n    <DataTable.Pagination />\n  </DataTable.Controls>\n</DataTable>\n```\n\nThis pattern acknowledges that not every table needs the full flexibility of the compositional approach and provides a simpler API for basic use cases.\n\n### Accessibility Considerations\n\n- I won't speak too much here (I'm not an expert; tables are hard) besides that we tried our best.\n- One clever solution was our approach to making table rows clickable (sometimes opening in a new tab, sometimes not).\n- You can't have nested interactive content like buttons in a clickable table row.\n- Rather than force a11y to its exact specifications at the cost of confusing code, we reframed it.\n- A11y is not about equality. It's about equity. There's a reason nested interactive content is bad.\n- Add an `onClick` to the row that screen readers wouldn't know about but sighted users would.\n- Have a button in the row that does the same thing as the `onClick`, so screen readers can still get there.\n- Two ways, same outcome.\n\n**Built-in Analytics**\n\nWe also got to implement user analytics (when did a user paginate, etc.) into the table. The most basic operations were batteries-included, and we provided a way to extend \"table actions\" to other actions that may be custom to an implementation.\n\nThese small bits of functionality that might get cut when up against a deadline are now provided for free. That's the power of building on a strong, shared platform!\n\n## Rollout Strategy\n\n### Adoption Challenges\n\nOne problem design systems teams have is adoption: you build what you think is a great component, but product teams still don't use it, maybe because it doesn't quite meet their needs, or because the effort involved in migrating isn't worth the cost.\n\n### Milestone-Driven Approach\n\n- We aligned our milestones with product team launches\n- Milestone 1 (Foundation): Simple table — our team already had a table that we owned for this\n- Milestone 2 (Basic features): Admin > Reviews > Templates table\n- Milestone 3 (Advanced features): Admin > Compensation > Benchmarking table\n- Milestone 4 (Enhancements): Net-new features like row grouping\n\nEach milestone had a specific product team attached, ensuring we were building for real use cases and had immediate feedback loops. Also, we were spreading knowledge to teams as well!\n\n## Outcomes\n\n### Initial Outcomes\n\n- Initial (and medium-term) feedback was positive!\n- We migrated a few tables ourselves, which was a great way to kick the tires\n- [For tracking component adoption, see my (future) article on tracking.]\n\n### What Could Have Gone Better\n\n- Aligning milestones to product teams was a great idea; I'd definitely do it again.\n- However, I think we over-indexed on those milestones. We provided white-glove service in a way that prioritized a single product team over others.\n- I think we could / should have moved much faster.\n\n### SimpleTable\n\n- One piece of feedback we got early on was that we needed to provide a simple component that just took in data\n- Sometimes backend engineers just want to pass in one argument and have the table. They don't want to make decisions.\n- So lean in more to components like SimpleTable\n- There's also power in forcing a way to do things vs. nudging product teams to do it a particular way\n- Plus, you avoid inconsistency off-the-bat!\n\n## Learnings\n\n### Organizational Insights\n\n- I changed my mind about where design system teams should be located.\n- Previously, I thought they needed to be in platform orgs because they were, well, a platform. I thought the failure mode for them being in product orgs would be that they would solve for that specific team instead of a generalized solution.\n- But when my team was moved into a product org, I discovered that the close alignment was actually an asset!\n- Not only were we closer to our customers and able to react to feedback faster, our LCM (least common manager) was much lower and could force alignment, like tying DS outcomes to product outcomes!\n- Ultimately, DS exists to achieve business goals, not build pure components or live in the \"right\" location.\n- Align yourselves with tailwinds by finding the champions in your org, and don't worry too much about org structure.\n- Early adopters are crucial: Identify them early, invest in them, and let them become your advocates\n- Milestone alignment with product teams: Ensures you're building for real use cases and have immediate feedback loops\n",
    "draft": true
  },
  {
    "slug": "codemods",
    "title": "Lint Rules, Codemods, and AI",
    "date": "2025-07-24",
    "excerpt": "Why I prefer lint rules over codemods and how I’m using AI for migrations.",
    "content": "\nMost of the work that frontend platform teams do is migrations. We’re constantly moving away from deprecated libraries and towards preferred patterns. It’d be impossible for a small team to manually do all this work! This is where automation comes in.\n\nHere’s a simple scenario: your team wants to provide a consistent DX for your component library. As part of this work, you’ve identified that the `size` prop should be `sm`, instead of the current single-character `s`. You may have hundreds of usages across the codebase. Maybe other components also use the single-character prop, which means you can’t just find-and-replace this value.\n\n```jsx\n// Existing code\n<Button size=\"s\" />\n\n// Desired code\n<Button size=\"sm\" />\n```\n\nFor this type of migration, I prefer auto-fixable lint rules over codemods. Let me explain why!\n\n## How Codemods and Lint Rules Work\n\nCodemods parse your code into an abstract syntax tree, traverse and manipulate it, and output modified code.\n\nThe two libraries that I’ve seen used are [jscodeshift](https://github.com/facebook/jscodeshift) and [ts-morph](https://ts-morph.com/), paired with [AST Explorer](https://astexplorer.net/). Here’s an example of what a codemod for the above might look like, for `ts-morph`:\n\n```javascript\n// loop through each file,\nproject.getSourceFiles().forEach((sourceFile) => {\n  sourceFile\n    // finding all elements,\n    .getDescendantsOfKind(SyntaxKind.JsxSelfClosingElement)\n    .forEach((jsxElement) => {\n      const tagName = jsxElement.getTagNameNode().getText()\n\n      // where the element name is \"Button\",\n      if (tagName === 'Button') {\n        const sizeAttr = jsxElement.getAttribute('size')\n\n        // and the \"size\" attribute has a value of \"s\",\n        if (sizeAttr && sizeAttr.getText() === 'size=\"s\"') {\n          jsxElement.replaceWithText(\n            // and replace that value with \"sm\" instead.\n            jsxElement.getText().replace('size=\"s\"', 'size=\"sm\"'),\n          )\n        }\n      }\n    })\n})\n```\n\nAfter a codemod runs, you commit the changed code and proceed with your code review process. It’s usually a good idea to also run other formatters like Prettier before committing, or before chaining multiple codemods. You also don’t have to run the codemod over your entire codebase at once, which means product teams have the ability to migrate over at their own pace.\n\nLint rules are really similar. Many people are introduced to lint rules via third-party rulesets, like [jsx-a11y](https://github.com/jsx-eslint/eslint-plugin-jsx-a11y). It’s also straightforward to write [custom lint rules](https://eslint.org/docs/latest/extend/custom-rules). Custom rules are really useful for targeting patterns unique to your codebase!\n\nThe main difference between codemods and lint rules is that lint rules can highlight errors without necessarily needing to fix them. These lint failures are flagged to your IDE or you can set up a CI check to fail on any errors. For the rest of this article, I’m going to be talking about auto-fixable lint rules, in contrast to lint rules that might flag an error but not provide an automated method of fixing the error.\n\n```javascript\ncreate(context) {\n  return {\n    // for each element,\n    JSXElement({ openingElement }: TSESTree.JSXElement) {\n      // where the element name is \"Button\",\n      if (\n        openingElement.name.type !== 'JSXIdentifier' ||\n        openingElement.name.name !== 'Button'\n      ) {\n        return\n      }\n\n      // and the \"size\" attribute has a value of \"s\",\n      const sizeAttr = openingElement.attributes.find(\n        (attr): attr is TSESTree.JSXAttribute =>\n          attr.type === 'JSXAttribute' &&\n          attr.name.type === 'JSXIdentifier' &&\n          attr.name.name === 'size' &&\n          attr.value?.type === 'Literal' &&\n          attr.value.value === 's',\n      )\n\n      if (sizeAttr) {\n        context.report({\n          node: sizeAttr,\n          messageId: 'useSmInsteadOfS',\n          // replace that value with \"sm\" instead.\n          fix: (fixer) => fixer.replaceText(sizeAttr.value!, '\"sm\"'),\n        })\n      }\n    },\n  }\n},\n```\n\n## Why Lint Rules Beat Codemods\n\nHere’s my hot take: I almost always prefer auto-fixable lint rules over using codemods directly. There are two main reasons for this: built-in progress tracking and regression prevention.\n\n**Tracking Progress**\n\nESLint allows us to more easily report on the status of a migration. By setting the rule to `warn`, we can identify how many more locations we have left to fix and ownership for those parts of the codebase. This lets us better plan out an incremental strategy that might involve other product teams.\n\n**Preventing Regressions**\n\nOnce enabled, the rule prevents new violations from being introduced. Codemods are one-shot; they don’t prevent future mistakes, and you may need to run them multiple times.\n\n**Caveats**\n\nAs with everything, there’s nuance here. One case when it may be helpful to use a codemod is when you want to migrate between two valid values (example: change all current `font-size: small` values to `font-size: medium`). You might want to one-shot these with a codemod, because you do want to allow for `small` font-sizes... just not for the old, existing code though. That said, you can still write an ESLint rule and run the auto-fix, and then not enable the rule.\n\n## AI’s Sweet Spot: ESLint Rules\n\nMy experience with using tools like Copilot or Cursor for migration work is that they aren’t great yet at making these types of changes, even if you provide detailed instructions. My hunch is that this is a core limitation of how they work: LLMs need to understand and rewrite the entire surrounding context, which is usually unnecessary.\n\nAdditionally, if you have a large number of call-sites that need to change, you won’t be able to make all the changes you want in the same context window and you have to figure out a way to parallelize anyway.\n\nHowever, LLMs have been great at writing lint rules, the same way they excel at writing bash scripts or regex. This way, you get the best of both worlds: development speed from the LLM and safety from the deterministic rule. LLMs can also write [test cases](https://eslint.org/docs/latest/integrate/nodejs-api#ruletester) for your lint rules.\n\nWhen writing lint rules for migration, I’d focus on capturing 80-90% of all cases, but not invest too much time fiddling with capturing _all_ cases and achieving perfection. At the end of the day, it’s the codebase that matters not the tools you used to get it there!\n\n## Migration Strategy\n\nSo, here’s how I might execute on our motivating problem. Each step roughly corresponds to what I'd expect a single PR to look like.\n\n1. Add code for allowing both the `sm` and `s` values for the `size` prop for our `Button` component\n2. Use AI to write an auto-fixable ESLint rule and set to `warn` for the entire codebase\n3. Run the autofix across codebase in sections, tagging the code-owning team when applicable, and setting the rule to `error` when the section is completely migrated\n4. Use AI to tackle any remaining edge cases\n5. Remove the old `s` prop from `Button` and prevent regressions at a Typescript level\n\nThis approach lets you roll out the change safely. Most of the work isn’t code-related but rather the process overhead of interacting with other teams.\n\n## Summary\n\n- Prefer lint rules over codemods for migrations since they’re better for tracking progress and preventing regressions\n- Lean on AI to help write deterministic lint rules rather than directly transform code\n- The hardest part of migrations is bringing other teams along, not the technical changes themselves\n",
    "draft": false
  },
  {
    "slug": "tell-me-about-a-time",
    "title": "Tell me about a time when...",
    "date": "2025-07-09",
    "content": "",
    "draft": true
  }
]

export function getAllPosts(): WritingPost[] {
  return posts.filter(post => !post.draft)
}

export function getPostBySlug(slug: string): WritingPost | null {
  return posts.find(post => post.slug === slug) || null
}
